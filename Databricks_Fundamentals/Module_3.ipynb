{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e00199",
   "metadata": {},
   "source": [
    "## Data Analytics Module 3 - Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afc28b",
   "metadata": {},
   "source": [
    "### Loading CSV file into dbfs (Databricks File System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7367873",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "rm -r /dbfs/delta_lab\n",
    "mkdir /dbfs/delta_lab\n",
    "wget -O /dbfs/delta_lab/products.csv https://raw.githubusercontent.com/kuljotSB/DatabricksGenAIEngineer/refs/heads/main/Databricks_Fundamentals/products.csv\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec85555",
   "metadata": {},
   "source": [
    "### Loading Data into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load('/delta_lab/products.csv', format='csv', header=True)\n",
    "display(df.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca67846",
   "metadata": {},
   "source": [
    "### Load the data into a delta table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae0b79d",
   "metadata": {},
   "source": [
    "#### Storing in DBFS (Databricks File System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce536d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_table_path = \"/delta/products-delta\" \n",
    "df.write.format(\"delta\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c1cb3f",
   "metadata": {},
   "source": [
    "#### Manipulating the Delta Table by creating a DeltaTable Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ef7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create a deltaTable object\n",
    "deltaTable = DeltaTable.forPath(spark, delta_table_path)\n",
    "# Update the table (reduce price of product 771 by 10%)\n",
    "deltaTable.update(\n",
    "   condition = \"ProductID == 771\",\n",
    "   set = { \"ListPrice\": \"ListPrice * 0.9\" })\n",
    "# View the updated data as a dataframe\n",
    "deltaTable.toDF().show(10)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7817398",
   "metadata": {},
   "source": [
    "### Creating a dataframe from the delta dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "new_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a37d18",
   "metadata": {},
   "source": [
    "### Explore Logging for the delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTable.history(10).show(10, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9a083",
   "metadata": {},
   "source": [
    "### Creating a Data Catalog Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b7c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").saveAsTable(\"default.ProductsManaged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d1db0",
   "metadata": {},
   "source": [
    "### Accessing the Data Catalog Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "USE default;\n",
    "SELECT * FROM ProductsManaged;"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
