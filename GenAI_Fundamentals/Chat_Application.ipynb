{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb71e455",
   "metadata": {},
   "source": [
    "## Creating a Chat Application with MLflow and OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5b521",
   "metadata": {},
   "source": [
    "![llm_chatbot_model_serving](./Assets/llm_chatbot_model_serving.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43864f2",
   "metadata": {},
   "source": [
    "### Installing Utilities and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11fe30",
   "metadata": {},
   "source": [
    "### Restarting our Python Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c10502",
   "metadata": {},
   "source": [
    "### Creating the OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826db0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = \"YOUR_DATABRICKS_ACCESS_TOKEN\",\n",
    "    base_url = \"YOUR_DATABRICKS_WORKSPACE_HOSTNAME/serving-endpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321940a",
   "metadata": {},
   "source": [
    "### Sending a Simple Chat Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Request\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"databricks-claude-sonnet-4-5\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\", \"text\": \"You are Batman, the protector of Gotham City\"\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\", \"text\": \"How's Gotham City doing today?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# printing the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629facb",
   "metadata": {},
   "source": [
    "### Generating a custom Python Function using MLflow that can be served as a Mosaic AI Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd79155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import pyfunc\n",
    "\n",
    "class BasicChatBot(pyfunc.PythonModel):\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def chatCompletionsAPI(self, user_query):\n",
    "        openai_client = OpenAI(\n",
    "            api_key = \"YOUR_DATABRICKS_ACCESS_TOKEN\",\n",
    "            base_url = \"YOUR_DATABRICKS_WORKSPACE_HOSTNAME/serving-endpoints\"\n",
    "        )\n",
    "\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model = self.model_name,\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\", \"text\": \"You are Batman, the protector of Gotham City\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\", \"text\": user_query\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def predict(self, context, data):\n",
    "        user_query = data[\"user_query\"].iloc[0]\n",
    "        gpt_response = self.chatCompletionsAPI(user_query)\n",
    "        return gpt_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a0568",
   "metadata": {},
   "source": [
    "### Saving our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = BasicChatBot(GPT_model=\"YOUR_MODEL_NAME\") # e.g., \"databricks-claude-sonnet-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fe8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "\n",
    "signature = infer_signature(pd.DataFrame([{\"user_query\": \"how is Gotham City today?\"}]))\n",
    "model_path = \"basicchatbot\"\n",
    "mlflow.pyfunc.save_model(path=model_path, python_model=test_model, signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922fe43",
   "metadata": {},
   "source": [
    "### Loading our Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our custom model from the local artifact store\n",
    "loaded_pyfunc_model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24563a92",
   "metadata": {},
   "source": [
    "### Testing our Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219bdcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = pd.DataFrame([{\"user_query\": \"hello how are you?\"}])\n",
    "\n",
    "model_response = loaded_pyfunc_model.predict(model_input)\n",
    "\n",
    "print(model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6f0ed",
   "metadata": {},
   "source": [
    "### Logging our Saved/Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd93a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Log the model as an artifact\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_artifacts(local_dir=model_path, artifact_path=\"BasicChatBot\")\n",
    "    print(f\"Model logged with run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69fdef",
   "metadata": {},
   "source": [
    "### Testing the Real-Time Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aa4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"dataframe_records\":[\n",
    "    {\n",
    "        \"user_query\":\"What is Joker doing in Gotham City today?\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
